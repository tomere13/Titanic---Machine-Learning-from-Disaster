{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5396cb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a952cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the data\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f80948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "# Extract Title from Name, replace rare titles with 'Rare'\n",
    "train_data['Title'] = train_data['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "test_data['Title'] = test_data['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "rare_titles = ['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona']\n",
    "train_data['Title'] = train_data['Title'].replace(rare_titles, 'Rare')\n",
    "test_data['Title'] = test_data['Title'].replace(rare_titles, 'Rare')\n",
    "\n",
    "# Create 'FamilySize' feature and 'IsAlone' feature\n",
    "train_data['FamilySize'] = train_data['SibSp'] + train_data['Parch'] + 1\n",
    "test_data['FamilySize'] = test_data['SibSp'] + test_data['Parch'] + 1\n",
    "train_data['IsAlone'] = 0\n",
    "train_data.loc[train_data['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "test_data['IsAlone'] = 0\n",
    "test_data.loc[test_data['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "# Fill NaN values in 'Age' column with the median age\n",
    "train_data['Age'].fillna(train_data['Age'].median(), inplace=True)\n",
    "test_data['Age'].fillna(test_data['Age'].median(), inplace=True)\n",
    "\n",
    "# Bin 'Age' into categories\n",
    "train_data['AgeBin'] = pd.cut(train_data['Age'].astype(int), 5, labels=['Child','Teenager','Adult','MiddleAged', 'Elderly'])\n",
    "test_data['AgeBin'] = pd.cut(test_data['Age'].astype(int), 5, labels=['Child','Teenager','Adult','MiddleAged', 'Elderly'])\n",
    "\n",
    "\n",
    "# Bin 'Age' into categories\n",
    "train_data['AgeBin'] = pd.cut(train_data['Age'].astype(int), 5, labels=['Child','Teenager','Adult','MiddleAged', 'Elderly'])\n",
    "test_data['AgeBin'] = pd.cut(test_data['Age'].astype(int), 5, labels=['Child','Teenager','Adult','MiddleAged', 'Elderly'])\n",
    "\n",
    "# Bin 'Fare' into categories\n",
    "train_data['FareBin'] = pd.qcut(train_data['Fare'], 4, labels=['Low', 'Medium', 'High', 'VeryHigh'])\n",
    "test_data['FareBin'] = pd.qcut(test_data['Fare'], 4, labels=['Low', 'Medium', 'High', 'VeryHigh'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1dab56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing for numeric columns (normalize them so they're on the same scale)\n",
    "numeric_features = ['FamilySize']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Define preprocessing for categorical features (encode them as one-hot vectors)\n",
    "categorical_features = ['Embarked', 'Sex', 'Pclass', 'Title', 'IsAlone', 'AgeBin', 'FareBin']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eea2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Split the data\n",
    "X = train_data.drop('Survived', axis=1)\n",
    "y = train_data['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e495edda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'classifier__max_depth': 5, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Create a preprocessing and classification pipeline\n",
    "rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RandomForestClassifier())])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [None, 5, 10, 15],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__max_features': ['sqrt']  # Changed 'auto' to 'sqrt'\n",
    "}\n",
    "\n",
    "\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=StratifiedKFold(n_splits=5))\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "# Use the best model to make predictions\n",
    "best_rf = grid_search.best_estimator_\n",
    "predictions = best_rf.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "20289c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.49 %\n",
      "Standard Deviation: 4.56 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = grid_search, X = X, y = y, cv = 10)\n",
    "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "94e09af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the passenger IDs and our prediction regarding whether they survived or not\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "output.to_csv('submission6.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec198efa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
